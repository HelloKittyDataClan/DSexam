from pandas import DataFrame, concat, read_csv, Series
from sqlite3 import connect
from rdflib import Namespace 
from rdflib.namespace import FOAF
from rdflib import Graph, URIRef, RDF, Namespace, Literal
from rdflib.plugins.stores.sparqlstore import SPARQLUpdateStore
import pandas as pd
import csv
import re

class Handler:                             #Chiara
    def __init__(self): 
        self.dbPathOrUrl = "" 

    def getDbPathOrUrl(self): 
        return self.dbPathOrUrl  
    
    def setDbPathOrUrl(self, pathOrUrl: str) -> bool:   
        if isinstance(pathOrUrl, str):
            self.dbPathOrUrl = pathOrUrl
            return True
        else:
            return False

class UploadHandler(Handler):
    def __init__(self):
        super().__init__()

    def pushDataToDb(self):
        pass

class MetadataUploadHandler(UploadHandler):         #Chiara
    def __init__(self):
        self.dbPathOrUrl = ""


    def pushDataToDb(self, path):
                
        #read the data from the csv file and store them into a dataframe --
        venus = pd.read_csv(
        path,
        keep_default_na=False,
        dtype={
                "Id": "string",
                "Type": "string",
                "Title": "string",
                "Date": "string",
                "Author": "string",
                "Owner": "string",
                "Place": "string",
            },
        )
    
        # Define namespaces
        base_url = Namespace("http://github.com/HelloKittyDataClan/DSexam") #  #our base url --
        db = Namespace ("http//dbpedia.org/resource/")
        FOAF = Namespace("http://xmlns.com/foaf/0.1/")  # related to person--
        schema = Namespace ("http://schema.org")

        # Create Graph
        meta_graph = Graph()
        meta_graph.bind("base_url", base_url)
        meta_graph.bind("dpedia", db)
        meta_graph.bind("FOAF", FOAF)
        meta_graph.bind ("schema", schema)
        
      
        # Define classes about Cultural Object ---
        Person = URIRef(FOAF.Person)
        NauticalChart = URIRef(base_url.NauticalChart)
        ManuscriptPlate = URIRef(base_url.ManuscriptPlate)
        ManuscriptVolume = URIRef(base_url.ManuscriptVolume)
        PrintedVolume = URIRef(base_url.PrintedVolume)
        PrintedMaterial = URIRef(base_url.PrintedMaterial)
        Herbarium = URIRef(db.Herbarium)
        Specimen = URIRef(base_url.Specimen)
        Painting = URIRef(db.Painting)
        Model = URIRef(db.Model)
        Map = URIRef(db.Map)

        # Attributes related to classes
        title = URIRef(schema.title)
        date = URIRef(schema.dataCreated)
        place = URIRef(schema.itemLocation)
        id = URIRef(schema.identifier)
        owner = URIRef(base_url.owner)

        # Relation with authors among classes
        author = URIRef(schema.author)

        # Attributes related to the class Person
        name = URIRef(FOAF.name)

 # Add to the graph the Cultural Object
        for idx, row in venus.iterrows():
            loc_id = "culturalobject-" + str(idx)
            subj = URIRef(base_url+loc_id)

            #assign object id
            meta_graph.add(subj, id, Literal(str(row["Id"])))

            #assign a resource classes to the object
            if row["Type"] != "":
                if row["Type"].lower() == "Nautical chart":
                    meta_graph.add((subj, RDF.type, NauticalChart))
                elif row["Type"].lower() == "Manuscript plate":
                    meta_graph.add((subj, RDF.type, ManuscriptPlate))
                elif row["Type"].lower() == "Manuscript volume":
                    meta_graph.add((subj, RDF.type, ManuscriptVolume))
                elif row["Type"].lower() == "Printed volume":
                    meta_graph.add((subj, RDF.type, PrintedVolume))
                elif row["Type"].lower() == "Printed material":
                    meta_graph.add((subj, RDF.type, PrintedMaterial))
                elif row["Type"].lower() == "Herbarium":
                    meta_graph.add((subj, RDF.type, Herbarium))
                elif row["Type"].lower() == "Specimen":
                     meta_graph.add((subj, RDF.type, Specimen))
                elif row["Type"].lower() == "Painting":
                    meta_graph.add((subj, RDF.type, Painting))
                elif row["Type"].lower() == "Model":
                    meta_graph.add((subj, RDF.type, Model))
                elif row["Type"].lower() == "Map":
                    meta_graph.add((subj, RDF.type, Map))

            #assign title
            if row["Title"] != "":
                meta_graph.add(subj, title, Literal(str(row["Title"].strip()))) #.strip() if there are white spaces

            #assign date
            if row["Date"] != "":
                meta_graph.add(subj, date, Literal(str(row["Date"])))

            #assign owner
            if row["Owner"] != "":
                meta_graph.add(subj, owner, Literal(str(row["Owner"])))

            #assign place
            if row["Place"] != "":
                meta_graph.add(subj, place, Literal(str(row["Place"])))

        # Dictionaries to track authors and associated objects
        authors_dict = dict()   
        people_object_ids = dict()
        people_counter = 0

        # Iterate over each row in the DataFrame
        for idx, row in venus.iterrows():
            
            # Extract information about authors
            if row["Author"] != "":
            # Split author string into a list of authors
                author_list = row["Author"].split(";")
                for author in author_list:
                    author_stripped = author.strip()
                    # Find the index of the opening parenthesis
                    indx_for_split = author_stripped.index("(")
                    # Extract the author name 
                    author_name = author_stripped[:indx_for_split-1].strip()
                    # Extract the id related to the author's name
                    author_id = author_stripped[indx_for_split+1:-1].strip()
                    object_id = row["Id"]
                    
                    if author_id in authors_dict.keys():
                      author_uri = authors_dict[author_id]
                      if object_id in people_object_ids.keys():
                          people_object_ids[object_id].append(author_uri)
                    else:
                          people_object_ids[object_id] = [author_uri]  
                else:
                    loc_id = "Person/" + str(people_counter)
                    subj = URIRef(base_url + loc_id)

                 # adding to the graph the type, id and the name of the person
                meta_graph.add((subj, RDF.type, Person))
                meta_graph.add((subj, id, Literal(str(author_id))))
                meta_graph.add((subj, name, Literal(str(author_name))))
                
                #to menage the author's duplicate and ensures that each author has a unique ID if the author ID is not already present in the authors_dict dictionary
                authors_dict[author_id] = subj
                if object_id in people_object_ids.keys():
                    people_object_ids[object_id].append(subj)
                else:
                    people_object_ids[object_id] = [subj]

                people_counter += 1
  
            if row["Author"] != "":
                authors = people_object_ids[row["Id"]]
                for auth in authors:
                    meta_graph.add((subj, author, auth))


        # Store RDF data in SPARQL endpoint
        #Utilizza una query SPARQL per contare direttamente il numero di triple nel database e memorizza il risultato in una variabile store_count.

            store = SPARQLUpdateStore()
       
            store.open((self.dbPathOrUrl, self.dbPathOrUrl))

            for triple in meta_graph.triples(None, None, None):
                store.add(triple)


        # Close the store connection
            store.close()
            return True
    
        except Exception as e:
            print("The upload of data to Blazegraph failed: " + str(e))
            return False
    


# java -server -Xmx1g -jar blazegraph.jar (terminal command to run Blazegraph)

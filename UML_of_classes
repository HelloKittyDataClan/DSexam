from pandas import DataFrame, concat, read_csv, Series
from rdflib import Namespace 
from rdflib.namespace import FOAF
from rdflib import Graph, URIRef, RDF, Namespace, Literal
from rdflib.plugins.stores.sparqlstore import SPARQLUpdateStore
import pandas as pd
import traceback
import csv
import re


class Handler:                             #Chiara
    def __init__(self): 
        self.dbPathOrUrl = "" 

    def getDbPathOrUrl(self): 
        return self.dbPathOrUrl  
    
    def setDbPathOrUrl(self, pathOrUrl: str) -> bool:   
        if isinstance(pathOrUrl, str):
            self.dbPathOrUrl = pathOrUrl
            return True
        else:
            return False

class UploadHandler(Handler):
    def __init__(self):
        super().__init__()

    def pushDataToDb(self):
        pass

class MetadataUploadHandler(UploadHandler):         #Chiara
    def __init__(self):
        self.dbPathOrUrl = ""


    def pushDataToDb(self, path):
        my_graph = Graph()
        #read the data from the csv file and store them into a dataframe --
        venus = pd.read_csv("../meta.csv", 
                path,
                keep_default_na=False,
                dtype={
                "Id": "string",
                "Type": "string",
                "Title": "string",
                "Date": "string",
                "Author": "string",
                "Owner": "string",
                "Place": "string",
            },
        )
    
        # Define namespaces
        base_url = Namespace("http://github.com/HelloKittyDataClan/DSexam/") #  #our base url --
        db = Namespace ("http//dbpedia.org/resource/")
        FOAF = Namespace("http://xmlns.com/foaf/0.1/")  # related to person--
        schema = Namespace ("http://schema.org/")

        # Create Graph

        my_graph.bind("base_url", base_url)
        my_graph.bind("dpedia", db)
        my_graph.bind("FOAF", FOAF)
        my_graph.bind ("schema", schema)
        
      
        # Define classes about Cultural Object ---
        Person = URIRef(FOAF + "Person")
        NauticalChart = URIRef(base_url + "NauticalChart")
        ManuscriptPlate = URIRef(base_url + "ManuscriptPlate")
        ManuscriptVolume = URIRef(base_url + "ManuscriptVolume")
        PrintedVolume = URIRef(base_url + "PrintedVolume")
        PrintedMaterial = URIRef(base_url + "PrintedMaterial")
        Herbarium = URIRef(db + "Herbarium")
        Specimen = URIRef(base_url + "Specimen")
        Painting = URIRef(db + "Painting")
        Model = URIRef(db + "Model")
        Map = URIRef(db + "Map")

        # Attributes related to classes
        title = URIRef(schema + "title")
        date = URIRef(schema + "dataCreated")
        place = URIRef(schema + "itemLocation")
        id = URIRef(schema + "identifier")
        owner = URIRef(base_url + "owner")

        # Relation with authors among classes
        author = URIRef(schema + "author")

        # Attributes related to the class Person
        name = URIRef(FOAF + "name")

 # Add to the graph the Cultural Object
        for idx, row in venus.iterrows():
            loc_id = "culturalobject-" + str(idx)
            subj = URIRef(base_url+loc_id)

            #assign object id
            my_graph.add(subj, id, Literal(str(row["Id"])))

            #assign a resource classes to the object
            if row["Type"] != "":
                if row["Type"].lower() == "Nautical chart":
                    my_graph.add((subj, RDF.type, NauticalChart))
                elif row["Type"].lower() == "Manuscript plate":
                    my_graph.add((subj, RDF.type, ManuscriptPlate))
                elif row["Type"].lower() == "Manuscript volume":
                    my_graph.add((subj, RDF.type, ManuscriptVolume))
                elif row["Type"].lower() == "Printed volume":
                    my_graph.add((subj, RDF.type, PrintedVolume))
                elif row["Type"].lower() == "Printed material":
                    my_graph.add((subj, RDF.type, PrintedMaterial))
                elif row["Type"].lower() == "Herbarium":
                    my_graph.add((subj, RDF.type, Herbarium))
                elif row["Type"].lower() == "Specimen":
                     my_graph.add((subj, RDF.type, Specimen))
                elif row["Type"].lower() == "Painting":
                    my_graph.add((subj, RDF.type, Painting))
                elif row["Type"].lower() == "Model":
                    my_graph.add((subj, RDF.type, Model))
                elif row["Type"].lower() == "Map":
                    my_graph.add((subj, RDF.type, Map))

            #assign title
            if row["Title"] != "":
                my_graph.add(subj, title, Literal(str(row["Title"].strip()))) #.strip() if there are white spaces

            #assign date
            if row["Date"] != "":
                my_graph.add(subj, date, Literal(str(row["Date"])))

            #assign owner
            if row["Owner"] != "":
                my_graph.add(subj, owner, Literal(str(row["Owner"])))

            #assign place
            if row["Place"] != "":
                my_graph.add(subj, place, Literal(str(row["Place"])))

        # Dictionaries to track authors and associated objects
        author_id_mapping = dict()   
        object_mapping = dict()
        people_counter = 0

        for idx, row in venus.iterrows():
            # Extract information about authors
            if row["Author"] != "":
                author_list = row["Author"].strip('\"').split(";")   # Split author string into a list of authors
                for author in author_list:
                    author_st = author.strip()
                    indx_id = author_st.index("(")   # Find the index of the opening parenthesis 
                    author_name = author_st[:indx_id-1]  # Extract the author name from the beginning of the string up to the opening parenthesis
                    author_id = author_st[indx_id+1:-1]   # Extract the id related to the author's name
                    
                    obj_id = row["Id"]
                    # Check if the author ID is already in the author_id_mapping dictionary
                    if author_id in author_id_mapping.keys():
                      author_uri = author_id_mapping[author_id]
                      if obj_id in object_mapping.keys():
                          object_mapping[obj_id].append(author_uri)  # append author uri
                    else:
                          object_mapping[obj_id] = [author_uri]       # initialize a new list with the author URI
                else:
                    #generate a new uri
                    loc_author_id = "Person/" + str(people_counter)
                    subj_author = URIRef(base_url + loc_author_id)


                 # adding to the graph the type, id and the name of the person
                my_graph.add((subj_author, RDF.type, Person))
                my_graph.add((subj_author, id, Literal(str(author_id))))
                my_graph.add((subj_author, name, Literal(str(author_name))))
                
               # Manage author duplicates and ensure each author has a unique ID
                author_id_mapping[author_id] = subj_author
                if obj_id in object_mapping.keys():
                    object_mapping[obj_id].append(subj_author)
                else:
                    object_mapping[obj_id] = [subj_author]

                people_counter += 1


        # Store RDF data in SPARQL endpoint
        #Utilizza una query SPARQL per contare direttamente il numero di triple nel database e memorizza il risultato in una variabile store_count.
        try:
            store = SPARQLUpdateStore()
            store.open((self.dbPathOrUrl, self.dbPathOrUrl))

            for triple in my_graph.triples(None, None, None):
                store.add(triple)

            # Chiudi la connessione allo store
            store.close()
            return True

        except Exception as e:
            print("Failed to upload data to Blazegraph: " + str(e))
            #traceback.print_exc()  # Stampa l'intero traceback per ottenere pi√π informazioni sull'errore
            return False


# java -server -Xmx1g -jar blazegraph.jar (terminal command to run Blazegraph)




    


# java -server -Xmx1g -jar blazegraph.jar (terminal command to run Blazegraph)
